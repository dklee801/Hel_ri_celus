# 음성인식 AI 부분 정리(STT)



## STT 원리

1. #### 소리 = 파동

![1_PkvxKtomXS4sR4HzMVL8gA](C:\Users\이동규\Desktop\1_PkvxKtomXS4sR4HzMVL8gA.gif)

"Hello" 라는 단어의 파동 중 작은 부분을 확대한 그림



초당 수천번을 읽어들여서 그 시점에서의 음파 높이를 숫자로 저장합니다. 



![Image for post](https://miro.medium.com/max/1000/1*JQoSkUIadHmCBZ-Xky62iQ.png)

각 숫자는 1/16000 초 간격에 대한 음파의 진폭(amplitude)을 나타냅니다.

즉 : 진폭을 수치화해서 파동의 형태를 나타낼 수있음.



2. #### 이제 전처리

   이제 각 숫자가 초당 1/16,000 간격에 대한 음파의 진폭을 나타내는 일련의 숫자들이 있습니다.

샘플링한 오디오를 20 밀리 초 길이로 잘라 그룹으로 만드는 것부터 시작하겠습니다. 다음은 오디오의 처음 20 밀리초 (즉, 최초 320 개의 샘플) 입니다:

![Image for post](https://miro.medium.com/max/1000/1*uHel1XG79OVBtge5pHLP1w.png)

이 레코딩은 단지 *1/50 초 길이*입니다. 그러나 이 짧은 레코딩 조차도 음성의 서로 다른 주파수가 복잡하게 뒤섞인 것입니다. 여기에는 낮은 음역, 중간 음역들이 있고 심지어 높은 음역도 몇 군데 나타납니다. 하지만 이러한 다양한 주파수가 혼합되어 복잡한 인간 언어의 음성을 구성합니다.

신경망이 이 데이터를 좀더 쉽게 처리할 수 있도록, 복잡한 음파를 구성 요소들로 분리하려고 합니다. 가장 낮은 음역, 그 다음 낮은 음역, 이런식으로 분리할 것입니다. 그런 다음 각 주파수 대역별(낮은 주파수에서 높은 주파수까지)로 분포된 에너지를 합산해서, 이 오디오 정보에 대한 일종의 *지문(fingerprint)*을 만듭니다.

누군가 피아노로 C 장조 화음을 연주하는 것을 녹음했다고 상상해보십시오. 이 소리는 도, 미, 솔 이 세가지 음들이 함께 섞여져 하나의 복잡한 소리로 만들어진 것입니다. 우리는 이 복잡한 소리를 개별 음으로 분해해서 도, 미, 솔이라는 것을 알아내고자 합니다. 우리가 하고자 하는 것이 바로 정확히 동일한 아이디어입니다.

푸리에 변환 (Fourier transform)이라고하는 수학 연산을 사용하면 이를 수행할 수 있습니다. 개별적인 음파로 분해된 후에는, 각각의 음파에 얼마나 많은 에너지가 포함되어 있는지를 합산합니다.



![Image for post](https://miro.medium.com/max/1000/1*4ZbwSOwewzurLo4aLOSntw.png)

- hello 전체에 대한 음성 스펙트럼



#### 3. 짧은 소리로부터 특징 인식하기

딥신경망(deep neural network)에 이를 제공(feed)할 것입니다. 신경망에 입력되는 데이터는 20 밀리초 단위의 오디오 조각입니다. 각각의 작은 오디오 조각마다 현재 발음되는 소리에 해당하는 문자가 무엇인지 찾게 될 것입니다.

RNN 이용

![Image for post](https://miro.medium.com/max/800/1*5sIjtQGhJ7WBpx-o0vYQcg.png)



### **나만의 음성 인식 시스템을 만들 수 있을까요?**

나쁜 품질의 마이크, 배경 잡음, 잔향(reverb)과 반향(echo), 다양한 말투(accent) 등과 같은 거의 무한한 문제를 극복해야 합니다. 이러한 모든 문제는 신경망이 처리 할 수 있도록 훈련 데이터에 포함되어 있어야만 합니다.

예가 있습니다: 큰 방에서 이야기 할 때, 당신은 소음때문에 무의식적으로 소리를 높인다는 것을 알고 있습니까? 인간은 어떻게 하더라도 이해하는 데 아무런 문제가 없지만, 이 특수한 경우를 처리하기 위해 신경망은 훈련이 필요합니다. 따라서 소음 때문에 고함을 지르는 사람들의 훈련 데이터가 필요합니다.

Siri, Google Now! 또는 Alexa의 수준으로 동작하는 음성 인식 시스템을 구축하려면 수백명의 사람을 고용해서 녹음을 해야만 얻을 수 있는 데이터보다 훨씬 *많은* 훈련 데이터가 필요합니다. 그리고 사용자들은 저품질의 음성 인식 시스템을 이해해 주지 않기 때문에, 이 문제를 간과해서는 안됩니다. 아무도 80% 수준으로 동작하는 음성 인식 시스템을 원하지 않습니다.

> 따라서 당신이 스타업 아이디어를 고민하고 있다면, Google과 경쟁할 나만의 음성 인식 시스템을 개발하는 것은 절대 추천하지 않습니다. 

